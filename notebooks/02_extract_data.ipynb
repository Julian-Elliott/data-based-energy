{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine, text\n",
    "import yaml\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database credentials from secrets.yaml\n",
    "with open('../config/secrets.yaml', 'r') as f:\n",
    "    secrets = yaml.safe_load(f)\n",
    "\n",
    "db_config = secrets.get('database', {})\n",
    "\n",
    "# Build connection string\n",
    "DB_HOST = db_config.get('host', 'localhost')\n",
    "DB_PORT = db_config.get('port', 3306)\n",
    "DB_USER = db_config.get('user', 'readonly')\n",
    "DB_PASS = db_config.get('password', '')\n",
    "DB_NAME = db_config.get('database', 'homeassistant')\n",
    "\n",
    "connection_string = f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "print(f\"Connecting to: {DB_HOST}:{DB_PORT}/{DB_NAME} as {DB_USER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test connection\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT VERSION()\"))\n",
    "    row = result.fetchone()\n",
    "    if row:\n",
    "        version = row[0]\n",
    "        print(f\"‚úÖ Connected to MariaDB: {version}\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to get database version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba87be",
   "metadata": {},
   "source": [
    "## 1. Explore Database Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tables\n",
    "df_tables = pd.read_sql(\"SHOW TABLES\", engine)\n",
    "print(\"üìã Tables in homeassistant database:\")\n",
    "for table in df_tables.iloc[:, 0]:\n",
    "    # Get row count for each table\n",
    "    count = pd.read_sql(f\"SELECT COUNT(*) as cnt FROM `{table}`\", engine).iloc[0, 0]\n",
    "    print(f\"   ‚Ä¢ {table}: {count:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51dc01c",
   "metadata": {},
   "source": [
    "## 2. States Data\n",
    "\n",
    "The `states` table contains all entity state changes, linked to:\n",
    "- `states_meta` - Entity ID mappings\n",
    "- `state_attributes` - JSON attributes for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview states_meta (entity ID mappings)\n",
    "df_entities = pd.read_sql(\"\"\"\n",
    "    SELECT metadata_id, entity_id \n",
    "    FROM states_meta \n",
    "    ORDER BY entity_id\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"Total entities tracked: {len(df_entities)}\")\n",
    "df_entities.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time range for extraction\n",
    "days_back = 7  # Adjust as needed\n",
    "end_time = datetime.now()\n",
    "start_time = end_time - timedelta(days=days_back)\n",
    "\n",
    "print(f\"üìÖ Extraction range:\")\n",
    "print(f\"   Start: {start_time}\")\n",
    "print(f\"   End:   {end_time}\")\n",
    "print(f\"   Days:  {days_back}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3930ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract complete state history with entity IDs and attributes\n",
    "query_states = \"\"\"\n",
    "SELECT \n",
    "    sm.entity_id,\n",
    "    s.state,\n",
    "    s.last_changed_ts,\n",
    "    s.last_updated_ts,\n",
    "    sa.shared_attrs\n",
    "FROM states s\n",
    "JOIN states_meta sm ON s.metadata_id = sm.metadata_id\n",
    "LEFT JOIN state_attributes sa ON s.attributes_id = sa.attributes_id\n",
    "WHERE s.last_updated_ts >= :start_ts\n",
    "  AND s.last_updated_ts <= :end_ts\n",
    "ORDER BY s.last_updated_ts\n",
    "\"\"\"\n",
    "\n",
    "# Execute query\n",
    "df_states = pd.read_sql(\n",
    "    text(query_states), \n",
    "    engine,\n",
    "    params={\n",
    "        'start_ts': start_time.timestamp(),\n",
    "        'end_ts': end_time.timestamp()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert timestamps\n",
    "df_states['last_changed'] = pd.to_datetime(df_states['last_changed_ts'], unit='s')\n",
    "df_states['last_updated'] = pd.to_datetime(df_states['last_updated_ts'], unit='s')\n",
    "df_states['domain'] = df_states['entity_id'].str.split('.').str[0]\n",
    "\n",
    "print(f\"üìä States extracted: {len(df_states):,} rows\")\n",
    "print(f\"\\nEvents by domain:\")\n",
    "print(df_states['domain'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "df_states.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f544ef6",
   "metadata": {},
   "source": [
    "## 3. Long-Term Statistics\n",
    "\n",
    "The `statistics` table contains hourly aggregated data for sensors that support it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a427d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistics metadata (which entities have statistics)\n",
    "df_stats_meta = pd.read_sql(\"\"\"\n",
    "    SELECT id, statistic_id, source, unit_of_measurement\n",
    "    FROM statistics_meta\n",
    "    ORDER BY statistic_id\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"Entities with long-term statistics: {len(df_stats_meta)}\")\n",
    "df_stats_meta.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d16b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract long-term statistics (hourly)\n",
    "query_statistics = \"\"\"\n",
    "SELECT \n",
    "    sm.statistic_id,\n",
    "    sm.unit_of_measurement,\n",
    "    s.start_ts,\n",
    "    s.mean,\n",
    "    s.min,\n",
    "    s.max,\n",
    "    s.sum,\n",
    "    s.state\n",
    "FROM statistics s\n",
    "JOIN statistics_meta sm ON s.metadata_id = sm.id\n",
    "WHERE s.start_ts >= :start_ts\n",
    "  AND s.start_ts <= :end_ts\n",
    "ORDER BY s.start_ts\n",
    "\"\"\"\n",
    "\n",
    "df_statistics = pd.read_sql(\n",
    "    text(query_statistics),\n",
    "    engine,\n",
    "    params={\n",
    "        'start_ts': start_time.timestamp(),\n",
    "        'end_ts': end_time.timestamp()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert timestamps\n",
    "df_statistics['timestamp'] = pd.to_datetime(df_statistics['start_ts'], unit='s')\n",
    "\n",
    "print(f\"üìä Statistics extracted: {len(df_statistics):,} rows\")\n",
    "df_statistics.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca50343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics by entity\n",
    "print(\"üìä Statistics records by entity:\")\n",
    "print(df_statistics['statistic_id'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238784e",
   "metadata": {},
   "source": [
    "## 4. Short-Term Statistics (5-minute resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract short-term statistics (5-minute intervals)\n",
    "query_short_term = \"\"\"\n",
    "SELECT \n",
    "    sm.statistic_id,\n",
    "    sm.unit_of_measurement,\n",
    "    s.start_ts,\n",
    "    s.mean,\n",
    "    s.min,\n",
    "    s.max,\n",
    "    s.sum,\n",
    "    s.state\n",
    "FROM statistics_short_term s\n",
    "JOIN statistics_meta sm ON s.metadata_id = sm.id\n",
    "WHERE s.start_ts >= :start_ts\n",
    "  AND s.start_ts <= :end_ts\n",
    "ORDER BY s.start_ts\n",
    "\"\"\"\n",
    "\n",
    "df_short_term = pd.read_sql(\n",
    "    text(query_short_term),\n",
    "    engine,\n",
    "    params={\n",
    "        'start_ts': start_time.timestamp(),\n",
    "        'end_ts': end_time.timestamp()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert timestamps\n",
    "df_short_term['timestamp'] = pd.to_datetime(df_short_term['start_ts'], unit='s')\n",
    "\n",
    "print(f\"üìä Short-term statistics: {len(df_short_term):,} rows\")\n",
    "df_short_term.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8a34f",
   "metadata": {},
   "source": [
    "## 5. Events Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get event types\n",
    "df_event_types = pd.read_sql(\"\"\"\n",
    "    SELECT event_type_id, event_type\n",
    "    FROM event_types\n",
    "    ORDER BY event_type\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"Event types tracked: {len(df_event_types)}\")\n",
    "df_event_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract events (can be large, so limiting)\n",
    "query_events = \"\"\"\n",
    "SELECT \n",
    "    et.event_type,\n",
    "    e.time_fired_ts,\n",
    "    ed.shared_data\n",
    "FROM events e\n",
    "JOIN event_types et ON e.event_type_id = et.event_type_id\n",
    "LEFT JOIN event_data ed ON e.data_id = ed.data_id\n",
    "WHERE e.time_fired_ts >= :start_ts\n",
    "  AND e.time_fired_ts <= :end_ts\n",
    "ORDER BY e.time_fired_ts\n",
    "LIMIT 100000\n",
    "\"\"\"\n",
    "\n",
    "df_events = pd.read_sql(\n",
    "    text(query_events),\n",
    "    engine,\n",
    "    params={\n",
    "        'start_ts': start_time.timestamp(),\n",
    "        'end_ts': end_time.timestamp()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert timestamps\n",
    "df_events['time_fired'] = pd.to_datetime(df_events['time_fired_ts'], unit='s')\n",
    "\n",
    "print(f\"üìä Events extracted: {len(df_events):,} rows\")\n",
    "print(f\"\\nEvents by type:\")\n",
    "print(df_events['event_type'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df07ca",
   "metadata": {},
   "source": [
    "## 6. Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eeeae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup export directory\n",
    "from pathlib import Path\n",
    "data_dir = Path('../data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(f\"üìÅ Export directory: {data_dir.resolve()}\")\n",
    "print(f\"üìÖ Timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3727620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all data to CSV\n",
    "exports = [\n",
    "    ('states', df_states),\n",
    "    ('statistics', df_statistics),\n",
    "    ('statistics_short_term', df_short_term),\n",
    "    ('events', df_events),\n",
    "]\n",
    "\n",
    "# Track successful exports for cleanup\n",
    "exported_files = []\n",
    "\n",
    "for name, df in exports:\n",
    "    if not df.empty:\n",
    "        filepath = data_dir / f'{name}_{timestamp}.csv'\n",
    "        df.to_csv(filepath, index=False)\n",
    "        exported_files.append((name, filepath))\n",
    "        print(f\"‚úÖ {name}: {len(df):,} rows ‚Üí {filepath.name}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {name}: No data to export\")\n",
    "\n",
    "# Clean up older exports if all current exports succeeded\n",
    "if len(exported_files) == len([e for e in exports if not e[1].empty]):\n",
    "    removed_count = 0\n",
    "    for name, _ in exported_files:\n",
    "        # Find older files with same prefix\n",
    "        pattern = f'{name}_*.csv'\n",
    "        for old_file in data_dir.glob(pattern):\n",
    "            # Skip current export\n",
    "            if f'_{timestamp}.csv' not in old_file.name:\n",
    "                old_file.unlink()\n",
    "                removed_count += 1\n",
    "    if removed_count > 0:\n",
    "        print(f\"\\nüßπ Cleaned up {removed_count} older export file(s)\")\n",
    "\n",
    "print(\"\\nüìä Export complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8783e3",
   "metadata": {},
   "source": [
    "## 7. Full Historical Export (Optional)\n",
    "\n",
    "For complete historical data without time limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f531373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to export ALL historical data (can be very large!)\n",
    "\n",
    "# Full states export\n",
    "# df_all_states = pd.read_sql(\"\"\"\n",
    "#     SELECT \n",
    "#         sm.entity_id,\n",
    "#         s.state,\n",
    "#         s.last_changed_ts,\n",
    "#         s.last_updated_ts,\n",
    "#         sa.shared_attrs\n",
    "#     FROM states s\n",
    "#     JOIN states_meta sm ON s.metadata_id = sm.metadata_id\n",
    "#     LEFT JOIN state_attributes sa ON s.attributes_id = sa.attributes_id\n",
    "#     ORDER BY s.last_updated_ts\n",
    "# \"\"\", engine)\n",
    "# \n",
    "# df_all_states.to_csv(data_dir / f'all_states_{timestamp}.csv', index=False)\n",
    "# print(f\"Exported {len(df_all_states):,} total state records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "engine.dispose()\n",
    "print(\"‚úÖ Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3679ce",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook extracted directly from MariaDB:\n",
    "1. **States** - Complete entity state history with attributes\n",
    "2. **Statistics** - Hourly aggregated data for supported sensors\n",
    "3. **Short-term Statistics** - 5-minute resolution data\n",
    "4. **Events** - System events with data\n",
    "\n",
    "### Advantages over REST API:\n",
    "- ‚ö° Much faster (single query vs many API calls)\n",
    "- üìä No time range limits\n",
    "- üîç Full access to raw data and attributes\n",
    "- üìà Direct access to statistics tables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
